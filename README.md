# A Jornada dos Dados

<div align="left">
 <p>
 üí° &nbsp; <b>Cen√°rio: ETL de Clientes</b>
 </p>
<img align="right" alt="Coding" width="400" src="https://github.com/JosiTubaroski/Pipeline_Airflow/blob/main/Airflow_ETL_20240902.png">

<p>
Imagine que voc√™ faz parte de uma for√ßa-tarefa de intelig√™ncia financeira, respons√°vel por proteger o sistema contra atividades suspeitas de lavagem de dinheiro.  


</p>
<p>
Todos os dias, um grande volume de dados de clientes √© gerado e precisa ser processado, transformado, e analisado cuidadosamente para garantir a seguran√ßa do sistema financeiro.
</p>
<p>
Para isso, voc√™ criou uma pipeline de dados para a Carga de Clientes, onde s√£o capturadas todas as informa√ß√µes da Base de Origem e transportada para uma base onde a an√°lise de dados ser√° posteriormente aplicada.
</p>
<p>
Nesse cen√°rios especifico, vamos realizar a leitura de um arquivo .csv que √© disponibilizado em um diretorio no servidor diariamente, transportar e tratar os dados no SQL Server. 
</p>


<br>
<br>
</div> 

#





 

## üí° Atividades da DAG:


### 1. Coleta de Dados: 
Armazenar o Nome e a Data do arquivo que sera lido para a carga de Clientes.

### 2. Coleta de Dados: 
Nesse etapa √© realizada a limpeza da tabela temporaria que receber√° todos os dados do arquivo de Clientes.
Essa tabela est√° preparada apenas para receber os dados do Modo que estiverem na origem.

### 3. Transferencia dos dados: 
Nessa etapa √© realizada a leitura dos dados de acordo com o nome definido na etapa 1.

### 4.  Transferencia dos dados: 
Os dados s√£o inseridos na tabela temporaria do banco de dados SQL Server.

### 5. Coleta de Dados: 
Armazenar o Nome e a Data do arquivo que sera lido para a carga de Detalhes do Clientes (Informa√ß√µes como Endere√ßo, Valor Renda, Valor Patrimonio) entre outros.

### 6. Coleta de Dados: 
Nesse etapa √© realizada a limpeza da tabela temporaria que receber√° todos os dados do arquivo de Detalhes Clientes.
Essa tabela est√° preparada apenas para receber os dados do Modo que estiverem na origem.

### 7. Transferencia dos dados: 
Nessa etapa √© realizada a leitura dos dados de acordo com o nome definido na etapa 5.

### 8.  Transferencia dos dados: 
Os dados s√£o inseridos na tabela temporaria de Detalhes Clientes do banco de dados SQL Server.

### 9. Limpeza e Tratamento dos dados: 
Nessa etapa √© executada uma procedure que realiza o tratamento dos dados, como formata√ß√£o de datas, limpeza de duplicidades entre outros.
Ap√≥s o tratameto os dados ser√£o inseridos ou atualizadas nas tabelas definitivas de Clientes e Detalhes Clientes.

### Abaixo est√£o a dag, os arquivos e a procedure que efetua as opera√ß√µes mencionadas acima.

<div> 
<p><a href="https://github.com/JosiTubaroski/Pipeline_Airflow/blob/main/Anexos/ETL_CLIENTES.py">01. Dag ETL CLIENTES </a></p>
</div> 

<div> 
<p><a href="https://github.com/JosiTubaroski/Pipeline_Airflow/blob/main/Anexos">02. Arquivo CLIENTES (cliente_20231019.csv) </a></p>
</div> 

<div> 
<p><a href="https://github.com/JosiTubaroski/Pipeline_Airflow/blob/main/Anexos">03. Arquivo DETALHES CLIENTES (detalhe_cliente_20231019.csv) </a></p>
</div> 



